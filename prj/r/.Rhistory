if (n > l) {
break
}
n <- n + 1
}
sms_raw <- data.frame(type=type, text=text)
sms_raw$type <- factor(sms_raw$type)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
inspect(sms_corpus[1:3])
corpus_clean <- tm_map(sms_corpus, tolower)
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, removePunctuation)
cospus_clean <- tm_map(corpus_clean, stripWhitespace)
inspect(corpus_clean[1:3])
sms_dtm <- DocumentTermMatrix(corpus_clean)
sms_raw_train <- sms_raw[1:4182, ]
sms_raw_test <- sms_raw[4183:5575, ]
sms_dtm_train <- sms_dtm[1:4182, ]
sms_dtm_test <- sms_dtm[4183:5574, ]
sms_corpus_train <- corpus_clean[1:4182]
sms_corpus_test <- corpus_clean[4183:5574]
prop.table(table(sms_raw_train$type))
prop.table(table(sms_raw_test$type))
#install.packages("wordcloud")
library(wordcloud)
wordcloud(sms_corpus_train, min.freq = 40, random.order = FALSE)
#install.packages("readtext")
#install.packages("tm")
library(readtext)
library(stringr)
library(tm)
sms <- readtext("../../dataset/smspam/SMSSpamCollection.txt")
text <- unlist(sms[2])
text1 <- str_remove(text, "Named chr ")
text_list <- unlist(strsplit(text1, "\n"))
l <- length(text_list)
n <- 1
type = c()
text = c()
repeat {
line <- unlist(strsplit(text_list[n], "\t"))
type <- c(type, line[1])
text <- c(text, line[2])
if (n > l) {
break
}
n <- n + 1
}
sms_raw <- data.frame(type=type, text=text)
sms_raw$type <- factor(sms_raw$type)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
inspect(sms_corpus[1:3])
corpus_clean <- tm_map(sms_corpus, tolower)
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, removePunctuation)
cospus_clean <- tm_map(corpus_clean, stripWhitespace)
inspect(corpus_clean[1:3])
sms_dtm <- DocumentTermMatrix(corpus_clean)
sms_raw_train <- sms_raw[1:4182, ]
sms_raw_test <- sms_raw[4183:5575, ]
sms_dtm_train <- sms_dtm[1:4182, ]
sms_dtm_test <- sms_dtm[4183:5574, ]
sms_corpus_train <- corpus_clean[1:4182]
sms_corpus_test <- corpus_clean[4183:5574]
prop.table(table(sms_raw_train$type))
prop.table(table(sms_raw_test$type))
#install.packages("wordcloud")
library(wordcloud)
wordcloud(sms_corpus_train, min.freq = 40, random.order = FALSE)
spam <- subset(sms_raw_train, type=="spam")
ham <- subset(sms_raw_train, type="ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
wordcloud(sms_corpus_train, min.freq = 40, random.order = FALSE)
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
View(sms_corpus)
findFreqTerms(sms_dtm_train, 5)
sms_dict <- Dictionary(findFreqTerms(sms_dtm_train, 5))
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary=sms_dict()))
library(Dicionary)
ham <- subset(sms_raw_train, type="ham")
library(Dictionary)
sms_dict <- findFreqTerms(sms_dtm_train, 5)
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary=sms_dict()))
sms_dict <- findFreqTerms(sms_dtm_train, 5)
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary=sms_dict()))
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary=sms_dict)
sms_test <- DocumentTermMatrix(sms_corpus_test, list(dictionary=sms_dict)
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary=sms_dict)
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary=sms_dict))
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary=sms_dict))
sms_test <- DocumentTermMatrix(sms_corpus_test, list(dictionary=sms_dict))
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x , levels=c(0,1), labels=c(""No"", ""Yes""))
return (x)
}
convert_counts <- function(x) {
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x , levels=c(0,1), labels=c("No", "Yes"))
return (x)
}
sms_train <- apply(sms_train, MARGIN=2, convert_counts)
sms_test <- apply(sms_test, MARGIN=2, convert_counts)
install.packages("e1071")
#install.packages("e1071")
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
sms_test_pred <- predict(sms_classifier, sms_test)
library(gmodels)
CrossTable(sms_test_pred, sms_raw_test$type, prop.chisq = FALSE, prop.t = FALSE, dnn=c('predicted', 'actual'))
CrossTable(sms_test_pred, sms_raw_test$type, prop.chisq = FALSE, prop.t = FALSE, dnn=c('predicted', 'actual'))
normlize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)) )
}
wdbc = read.csv("../../dataset/WDBC/WDBC.dat")
wdbc <- wdbc[2:32]
wdbc_n <- as.data.frame(lapply(wdbc[2:31], normlize))
wdbc_train <- wdbc_n[1:469, ]
wdbc_test <- wdbc_n[470:568, ]
wdbc_train_labels <- wdbc_n[1:469, 1]
wdbc_test_labels <- wdbc_n[470:568, 1]
library("class")
wdbc_pred <- knn(train=wdbc_train, test=wdbc_test, cl=wdbc_train_labels, k=3)
wdbc_test_pred <- knn(train=wdbc_train, test=wdbc_test, cl=wdbc_train_labels, k=21)
library("gmodels")
CrossTable(x=wdbc_test_labels, y=wdbc_test_pred, prop.chisq=FALSE)
getwd()
CrossTable(x=wdbc_test_labels, y=wdbc_test_pred, prop.chisq=FALSE)
''
""
''
)
CrossTable(sms_test_pred, sms_raw_test$type, prop.chisq = FALSE, prop.t = FALSE, dnn=c('predicted', 'actual'))
library(gmodels)
CrossTable(sms_test_pred, sms_raw_test$type, prop.chisq = FALSE, prop.t = FALSE, dnn=c('predicted', 'actual'))
normlize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)) )
}
wdbc = read.csv("../../dataset/WDBC/WDBC.dat")
wdbc <- wdbc[2:32]
wdbc_n <- as.data.frame(lapply(wdbc[2:31], normlize))
wdbc_train <- wdbc_n[1:469, ]
wdbc_test <- wdbc_n[470:568, ]
wdbc_train_labels <- wdbc_n[1:469, 1]
wdbc_test_labels <- wdbc_n[470:568, 1]
library("class")
wdbc_pred <- knn(train=wdbc_train, test=wdbc_test, cl=wdbc_train_labels, k=3)
wdbc_test_pred <- knn(train=wdbc_train, test=wdbc_test, cl=wdbc_train_labels, k=21)
library("gmodels")
CrossTable(x=wdbc_test_labels, y=wdbc_test_pred, prop.chisq=FALSE)
#install.packages("readtext")
#install.packages("tm")
library(readtext)
library(stringr)
library(tm)
sms <- readtext("../../dataset/smspam/SMSSpamCollection.txt")
text <- unlist(sms[2])
text_list <- unlist(strsplit(text1, "\n"))
text1 <- str_remove(text, "Named chr ")
l <- length(text_list)
n <- 1
type = c()
repeat {
line <- unlist(strsplit(text_list[n], "\t"))
type <- c(type, line[1])
text <- c(text, line[2])
if (n > l) {
break
}
n <- n + 1
}
l <- length(text_list)
n <- 1
type = c()
text = c()
repeat {
line <- unlist(strsplit(text_list[n], "\t"))
type <- c(type, line[1])
text <- c(text, line[2])
if (n > l) {
break
}
n <- n + 1
}
sms_raw <- data.frame(type=type, text=text)
sms_raw$type <- factor(sms_raw$type)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
inspect(sms_corpus[1:3])
corpus_clean <- tm_map(sms_corpus, tolower)
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, removePunctuation)
cospus_clean <- tm_map(corpus_clean, stripWhitespace)
inspect(corpus_clean[1:3])
sms_dtm <- DocumentTermMatrix(corpus_clean)
sms_raw_train <- sms_raw[1:4182, ]
sms_raw_test <- sms_raw[4183:5575, ]
sms_dtm_train <- sms_dtm[1:4182, ]
sms_dtm_test <- sms_dtm[4183:5574, ]
sms_corpus_train <- corpus_clean[1:4182]
sms_corpus_test <- corpus_clean[4183:5574]
prop.table(table(sms_raw_train$type))
prop.table(table(sms_raw_test$type))
#install.packages("wordcloud")
library(wordcloud)
wordcloud(sms_corpus_train, min.freq = 40, random.order = FALSE)
spam <- subset(sms_raw_train, type=="spam")
ham <- subset(sms_raw_train, type="ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
findFreqTerms(sms_dtm_train, 5)
sms_dict <- findFreqTerms(sms_dtm_train, 5)
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary=sms_dict))
sms_test <- DocumentTermMatrix(sms_corpus_test, list(dictionary=sms_dict))
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x , levels=c(0,1), labels=c("No", "Yes"))
return (x)
}
sms_train <- apply(sms_train, MARGIN=2, convert_counts)
sms_test <- apply(sms_test, MARGIN=2, convert_counts)
#install.packages("e1071")
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
sms_test_pred <- predict(sms_classifier, sms_test)
library(gmodels)
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
sms_test_pred <- predict(sms_classifier, sms_test)
sms_test_pred <- predict(sms_classifier, sms_test)
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
#install.packages("e1071")
library(e1071)
install.packages("e1071")
#library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
#install.packages("e1071")
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
sms_test_pred <- predict(sms_classifier, sms_test)
library(gmodels)
CrossTable(sms_test_pred, sms_raw_test$type, prop.chisq = FALSE, prop.t = FALSE, dnn=c('predicted', 'actual'))
length(sms_test_pred)
length(sms_raw_test$type)
#install.packages("readtext")
#install.packages("tm")
library(readtext)
library(stringr)
library(tm)
sms <- readtext("../../dataset/smspam/SMSSpamCollection.txt")
text <- unlist(sms[2])
text1 <- str_remove(text, "Named chr ")
text_list <- unlist(strsplit(text1, "\n"))
l <- length(text_list)
n <- 1
type = c()
text = c()
repeat {
line <- unlist(strsplit(text_list[n], "\t"))
type <- c(type, line[1])
text <- c(text, line[2])
if (n > l) {
break
}
n <- n + 1
}
sms_raw <- data.frame(type=type, text=text)
sms_raw$type <- factor(sms_raw$type)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
inspect(sms_corpus[1:3])
corpus_clean <- tm_map(sms_corpus, tolower)
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, removePunctuation)
cospus_clean <- tm_map(corpus_clean, stripWhitespace)
inspect(corpus_clean[1:3])
sms_dtm <- DocumentTermMatrix(corpus_clean)
sms_raw_train <- sms_raw[1:4182, ]
sms_raw_test <- sms_raw[4183:5575, ]
sms_dtm_train <- sms_dtm[1:4182, ]
sms_dtm_test <- sms_dtm[4183:5575, ]
sms_corpus_train <- corpus_clean[1:4182]
sms_corpus_test <- corpus_clean[4183:5575]
prop.table(table(sms_raw_train$type))
prop.table(table(sms_raw_test$type))
#install.packages("wordcloud")
library(wordcloud)
wordcloud(sms_corpus_train, min.freq = 40, random.order = FALSE)
spam <- subset(sms_raw_train, type=="spam")
ham <- subset(sms_raw_train, type="ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
findFreqTerms(sms_dtm_train, 5)
sms_dict <- findFreqTerms(sms_dtm_train, 5)
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary=sms_dict))
sms_test <- DocumentTermMatrix(sms_corpus_test, list(dictionary=sms_dict))
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x , levels=c(0,1), labels=c("No", "Yes"))
return (x)
}
sms_train <- apply(sms_train, MARGIN=2, convert_counts)
sms_test <- apply(sms_test, MARGIN=2, convert_counts)
#install.packages("e1071")
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
sms_test_pred <- predict(sms_classifier, sms_test)
library(gmodels)
CrossTable(sms_test_pred, sms_raw_test$type, prop.chisq = FALSE, prop.t = FALSE, dnn=c('predicted', 'actual'))
sms_classifier
View(sms_classifier)
CrossTable(sms_test_pred, sms_raw_test$type, prop.chisq = FALSE, prop.t = FALSE, dnn=c('predicted', 'actual'))
typeof(sms_classifier)
clf <- unlist(sms_classifier)
typeof(clf)
clf[2]
clf[3]
clf[1]
clf[2]
clf[3]
clf[34]
sms_classifier$tables
typeof(sms_classifier$tables)
t <- sms_classifier$tables
t
t[1]
t[1][1]
typeof(t[1])
t[1]$available
t[1]$available[1]
length(t[1])
length(t)
length(t)
t
t[1]
t[1][1]
t[1]$available[1]
t <- sms_classifier$tables
counts <- length(t_a)
counts <- length(t)
c <- 1
tn <- c()
fp <- c()
fn <- c()
tp <- c()
repeat {
avail <- t$available
tn <- c(tn, avail[1])
fp <- c(fp, avail[2])
fn <- c(fn, avail[3])
tp <- c(tp, avail[4])
if (c > counts) {
break
}
c <- c + 1
}
df <- data.frame(tn=tn, fp=fp, fn=fn, tp=tp)
library(ggplot2)
ggplot(df, aes=(tn,fp,fn,tp)) + geom_line()
ggplot(df, aes(tn,fp,fn,tp)) + geom_line()
ggplot(df, aes(tn,fp,fn,tp)) + geom_point()
df
df$tn
ggplot(df, aes(tn)) + geom_point()
ggplot(df, aes(fp, fn)) + geom_point()
ggplot(df, aes(fp, fn,colour = class)) + geom_point()
log2(0.1)
p = 0.1
e <- -p * log2(p)
e
p <- 0.1
e <- -p * log2(p)
e
p <- seq(0, 1, 0.1)
e <- -p * log2(p)
e
p <- seq(0, 1, 0.01)
e <- -p * log2(p)
e
plot(p, e, type="l")
p <- seq(0, 1, 0.01)
p
e
curve(e, col="read")
e
curve(-p * log2(p), col="read")
curve(-p * log2(p), col="red")
x <- p
curve(-x * log2(x), col="red")
curve(-x * log2(x), col="red", xlab="x")
curve(-x * log2(x), col="red", xlab="x", yloab="entropy")
curve(-x * log2(x), col="red", xlab="x", ylab="entropy")
curve(-x * log2(x), col="red", xlab="x", ylab="entropy", lwd=4)
data <- read.csv('../../dataset/credit.csv')
data
View(data)
credit <- read.csv('../../dataset/credit.csv')
typeof(credit)
table(credit$checking_balance)
credit$checking_balance
table(credit$checking_balance)
table(credit$savings_balance)
summary(credit$months_loan_duration)
summary(credit$amount)
table(credit$default)
set.seed(12345)
credit_rand <- credit[order(runif(1000)),]
summary(credit_rand$amount)
summary(credit_rand$amount)
head(credit$amount)
head(credit_rand$amount)
credit_train <- credit_rand[1:900,]
credit_test <- credit_rand[901:1000,]
prop.table(table(credit_train$default))
prop.table(table(credit_train$default))
prop.table(table(credit_test$default))
install.packages("C50")
library(C50)
library(C50)
credit_modle <- C5.0(credit_train[-17], credit_train$default)
credit_model <- C5.0(credit_train[-17], credit_train$default)
typeof(credit_train$defautl)
typeof(credit_train$default)
credit_train$defautl
credit_train$default
table(credit$default)
factor(credit_train$default, c("no", "yes"))
factor(credit_train$default, levels=c("no", "yes"), lables=c(1, 2))
factor(credit_train$default, levels=c("no", "yes"), labels=c(1, 2))
levels(credit_train$default)
table(credit_train$default)
as.factor(credit_train$default)
credit_rand$default <- as.factor(credit_rand$default)
credit_train <- credit_rand[1:900,]
credit_test <- credit_rand[901:1000,]
prop.table(table(credit_train$default))
prop.table(table(credit_test$default))
install.packages("C50")
#install.packages("C50")
library(C50)
credit_model <- C5.0(credit_train[-17], credit_train$default)
typeof(credit_train$default)
credit_train$default
install.packages("C50")
install.packages("C50")
as.factor(credit_train$default)
#install.packages("C50")
library(C50)
credit_model <- C5.0(credit_train[-17], credit_train$default)
typeof(credit_train$default)
credit_train$default
credit_model
summary(credit_model)
credit_pred <- predict(credit_model, credit_test)
library(gmodels)
CrossTable(credit_test$,default, credit_pred, prop.chisq=FALSE, prop.c=FALSE, prop.r=FALSE, dnn=c('autual default', 'predicted default'))
CrossTable(credit_test$default, credit_pred,
prop.chisq=FALSE, prop.c=FALSE, prop.r=FALSE,
dnn=c('autual default', 'predicted default'))
mushrooms <- read.csv('../../dataset/mushrooms.csv', stringsAsFactors = TRUE)
typeof(mushrooms)
mushrooms$veil_type
mushrooms$veil_type <- NULL
table(mushrooms)
table(mushrooms$type)
summary(table)
summary(table$type)
summary(mushrooms)
table(mushrooms$type)
length(mushrooms)
library(RWeka)
install.packages("RWeka")
library(RWeka)
#install.packages('RWeka')
mushrooms_1R <- OneR(type ~ ., data=mushrooms)
length(mushrooms$type)
length(mushrooms$type) * 0.9
length(mushrooms$type)
mushrooms_train <- mushrooms[1:7312,]
mushrooms_test <- mushrooms[7313:8142,]
install.packages('RWeka')
#install.packages('RWeka')
mushrooms_1R <- OneR(type ~ ., data=mushrooms)
library(RWeka)
install.packages('RWeka')
mushrooms_1R <- OneR(type ~ ., data=mushrooms)
library(RWeka)
insuracne <- read.csv('../../dataset/insuracne.csv', stringsAsFactors = TRUE)
insurance <- read.csv('../../dataset/insurance.csv', stringsAsFactors = TRUE)
str(insurance)
print(insurance)
str(insurance)
summary(insurance$charges)
hist(insurance$charges)
talbe(insurance$region)
table(insurance$region)
table(insurance$charges)
str(insurance)
table(insurance$age)
str(insurance)
table(insurance$sex)
table(insurance$smoker)
cor(insurance[c('age', 'bmi', 'children', 'charges')])
paris(insurance[c('age', 'bmi', 'children', 'charges')])
pairs(insurance[c('age', 'bmi', 'children', 'charges')])
install.packages('psych')
library(psych)
psych_panle(insurance[c('age', 'bmi', 'children', 'charges')])
psych_panles(insurance[c('age', 'bmi', 'children', 'charges')])
psych_panels(insurance[c('age', 'bmi', 'children', 'charges')])
pairs.panels(insurance[c('age', 'bmi', 'children', 'charges')])
ins_models <- lm(charges ~ age+children+bmi+sex+smoker+region, data=insurance)
summary(ins_models)
